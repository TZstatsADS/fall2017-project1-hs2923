dtm <- removeSparseTerms(dtm, 0.4)
dim(dtm)
inspect(dtm[1:5, 10:13])
dtm.df <- as.data.frame(as.matrix(dtm))
# Chunk 12
InaugurationInfo$Key <- paste("inaug", InaugurationInfo$File, "-",InaugurationInfo$Term, ".txt", sep = "")
dtm.df$Key <- rownames(dtm.df) #Creates a key which will be used to link the tables
dtm.df <- merge(x = dtm.df, y = InaugurationInfo[,c(4,6)])
#Reshape and adequate the dataframe format before merging
ds <- reshape(dates.speeches, direction = "long", varying = list(2:5), v.names = "SpeechDates")
ds <- ds[!ds$SpeechDates == "", c(1:3)]
ds$SpeechDates <- as.Date(ds$SpeechDates, "%m/%d/%Y")
names(ds) <- c("President", "Term", "SpeechDate")
ds$Key <- paste("inaug", sapply(ds$President, gsub, pattern = " ", replacement = ""), "-",ds$Term, ".txt", sep = "")
# Chunk 13
par(mfrow = c(1,2))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Republican"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Republicans", x = 0.5, y = 1.1, cex = 2)
# Chunk 14
Cluster.model <- kmeans(dtm, 3)
Cluster.model2 <- kmeans(dtm, 4)
dtm.df$Cluster1 <- Cluster.model$cluster
dtm.df$Cluster2 <- Cluster.model2$cluster
# Chunk 15
PCA.model <- prcomp(dtm)
plot(PCA.model$sdev, type = "l", col = "blue")
points(PCA.model$sdev, pch = 22, bg = "red")
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Party)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster1)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster2)))
par(mfrow = c(1,2))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Republican"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
names(dtm.df[which(dtm.df$Party == "Democratic"),2:151]
)
par(mfrow = c(1,2))
wordcloud(words = rownames(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = rownames(dtm.df[which(dtm.df$Party == "Republican"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
rownames(dtm.df[which(dtm.df$Party == "Democratic"),2:151])
View(dtm.df)
dtm.df <- merge(x = dtm.df, y = InaugurationInfo[,c(4,6)])
View(dtm.df)
par(mfrow = c(1,2))
wordcloud(words = rownames(dtm.df[which(dtm.df$Party == "Democratic"), 3:96]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"), 3:96]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
par(mfrow = c(1,2))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"), 3:96]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"), 3:96]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Republican"),2:151]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"),2:151]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
# Chunk 1
packages.used=c("tm", "wordcloud", "fpc",
"ggplot2", "RCurl", "xlsx")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(fpc)
library(ggplot2)
library(RCurl)
library(xlsx)
# Chunk 2
#Reading file with speech dates from local directory
dir1 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InauguationDates.txt"
dates.speeches <- read.table(dir1, header = T, skip = 1, sep = "\t")
#Reading Information file from local directory
dir2 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InaugurationInfo.xlsx"
InaugurationInfo <- read.xlsx(dir2, sheetIndex = 1)
rm(dir1,dir2)
# Chunk 3: setup
#Importing Speech data
dir3 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InauguralSpeeches"
doc <- DirSource(directory = dir3, encoding = "UTF-8", pattern = "\\.txt$"); rm(dir3)
ovid <- VCorpus(doc, readerControl = list(language = "en"))
# Chunk 4
ovid
inspect(ovid[1])
# Chunk 5
ovid.t <- ovid   #Renaming corpus
ovid.t <- tm_map(ovid.t, content_transformer(tolower))
ovid.t <- tm_map(ovid.t, removeWords, stopwords("english"))
ovid.t <- tm_map(ovid.t, removePunctuation, preserve_intra_word_dashes = T)
ovid.t <- tm_map(ovid.t, stripWhitespace)
# Chunk 6
# Chunk 7
dtm <- DocumentTermMatrix(ovid.t) #Function to create matrix
dim(dtm)
# Chunk 8
inspect(dtm[1:5, 10:13])
# Chunk 9
findFreqTerms(dtm, 150)
# Chunk 10
wordcloud(tm_map(ovid.t, PlainTextDocument), min.freq=100, scale=c(5,2),
random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
# Chunk 11
dtm <- removeSparseTerms(dtm, 0.4)
dim(dtm)
inspect(dtm[1:5, 10:13])
dtm.df <- as.data.frame(as.matrix(dtm))
# Chunk 12
InaugurationInfo$Key <- paste("inaug", InaugurationInfo$File, "-",InaugurationInfo$Term, ".txt", sep = "")
dtm.df$Key <- rownames(dtm.df) #Creates a key which will be used to link the tables
dtm.df <- merge(x = dtm.df, y = InaugurationInfo[,c(4,6)])
#Reshape and adequate the dataframe format before merging
ds <- reshape(dates.speeches, direction = "long", varying = list(2:5), v.names = "SpeechDates")
ds <- ds[!ds$SpeechDates == "", c(1:3)]
ds$SpeechDates <- as.Date(ds$SpeechDates, "%m/%d/%Y")
names(ds) <- c("President", "Term", "SpeechDate")
ds$Key <- paste("inaug", sapply(ds$President, gsub, pattern = " ", replacement = ""), "-",ds$Term, ".txt", sep = "")
# Chunk 13
par(mfrow = c(1,2))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"), 3:96]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"), 3:96]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Republican"), 3:96]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"), 3:96]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Republicans", x = 0.5, y = 1.1, cex = 2)
# Chunk 14
Cluster.model <- kmeans(dtm, 3)
Cluster.model2 <- kmeans(dtm, 4)
dtm.df$Cluster1 <- Cluster.model$cluster
dtm.df$Cluster2 <- Cluster.model2$cluster
# Chunk 15
PCA.model <- prcomp(dtm)
plot(PCA.model$sdev, type = "l", col = "blue")
points(PCA.model$sdev, pch = 22, bg = "red")
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Party)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster1)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster2)))
rm(list=ls())
packages.used=c("tm", "wordcloud", "fpc",
"ggplot2", "RCurl", "xlsx")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(fpc)
library(ggplot2)
library(RCurl)
library(xlsx)
#Reading file with speech dates from local directory
dir1 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InauguationDates.txt"
dates.speeches <- read.table(dir1, header = T, skip = 1, sep = "\t")
#Reading Information file from local directory
dir2 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InaugurationInfo.xlsx"
InaugurationInfo <- read.xlsx(dir2, sheetIndex = 1)
rm(dir1,dir2)
#Importing Speech data
dir3 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InauguralSpeeches"
doc <- DirSource(directory = dir3, encoding = "UTF-8", pattern = "\\.txt$"); rm(dir3)
ovid <- VCorpus(doc, readerControl = list(language = "en"))
ovid
inspect(ovid[1])
ovid.t <- ovid   #Renaming corpus
ovid.t <- tm_map(ovid.t, content_transformer(tolower))
ovid.t <- tm_map(ovid.t, removeWords, stopwords("english"))
ovid.t <- tm_map(ovid.t, removePunctuation, preserve_intra_word_dashes = T)
ovid.t <- tm_map(ovid.t, stripWhitespace)
dtm <- DocumentTermMatrix(ovid.t) #Function to create matrix
dim(dtm)
inspect(dtm[1:5, 10:13])
findFreqTerms(dtm, 150)
wordcloud(tm_map(ovid.t, PlainTextDocument), min.freq=100, scale=c(5,2),
random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
dtm <- removeSparseTerms(dtm, 0.4)
dim(dtm)
inspect(dtm[1:5, 10:13])
dtm.df <- as.data.frame(as.matrix(dtm))
InaugurationInfo$Key <- paste("inaug", InaugurationInfo$File, "-",InaugurationInfo$Term, ".txt", sep = "")
dtm.df$Key <- rownames(dtm.df) #Creates a key which will be used to link the tables
dtm.df <- merge(x = dtm.df, y = InaugurationInfo[,c(4,6)])
#Reshape and adequate the dataframe format before merging
ds <- reshape(dates.speeches, direction = "long", varying = list(2:5), v.names = "SpeechDates")
ds <- ds[!ds$SpeechDates == "", c(1:3)]
ds$SpeechDates <- as.Date(ds$SpeechDates, "%m/%d/%Y")
names(ds) <- c("President", "Term", "SpeechDate")
ds$Key <- paste("inaug", sapply(ds$President, gsub, pattern = " ", replacement = ""), "-",ds$Term, ".txt", sep = "")
par(mfrow = c(1,2))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"), 3:94]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"), 3:94]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Republican"), 3:94]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"), 3:94]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Republicans", x = 0.5, y = 1.1, cex = 2)
?colSums
View(dtm.df)
a <- sapply(x, is.numeric)
a <- sapply(dtm.df, is.numeric)
a <- which(sapply(dtm.df, is.numeric))
a
?kmeans
Cluster.model <- kmeans(dtm, 3, iter.max = 15, nstart = 10)
Cluster.model2 <- kmeans(dtm, 4, iter.max = 15, nstart = 10)
dtm.df$Cluster1 <- Cluster.model$cluster
dtm.df$Cluster2 <- Cluster.model2$cluster
Cluster.model2 <- kmeans(dtm, 2, iter.max = 15, nstart = 10)
Cluster.model3 <- kmeans(dtm, 3, iter.max = 15, nstart = 10)
dtm.df$Cluster2 <- Cluster.model2$cluster
dtm.df$Cluster3 <- Cluster.model3$cluster
rm(list=ls())
# Chunk 1
packages.used=c("tm", "wordcloud", "fpc",
"ggplot2", "RCurl", "xlsx")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(fpc)
library(ggplot2)
library(RCurl)
library(xlsx)
# Chunk 2
#Reading file with speech dates from local directory
dir1 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InauguationDates.txt"
dates.speeches <- read.table(dir1, header = T, skip = 1, sep = "\t")
#Reading Information file from local directory
dir2 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InaugurationInfo.xlsx"
InaugurationInfo <- read.xlsx(dir2, sheetIndex = 1)
rm(dir1,dir2)
# Chunk 3: setup
#Importing Speech data
dir3 <- "D:/Google Drive/Google Drive/My Files/2) Estudos/4) Columbia/3) Classes/4) Fall 2017/1) Applied Data Science/1) GitHub/fall2017-project1-hs2923/data/InauguralSpeeches"
doc <- DirSource(directory = dir3, encoding = "UTF-8", pattern = "\\.txt$"); rm(dir3)
ovid <- VCorpus(doc, readerControl = list(language = "en"))
# Chunk 4
ovid
inspect(ovid[1])
# Chunk 5
ovid.t <- ovid   #Renaming corpus
ovid.t <- tm_map(ovid.t, content_transformer(tolower))
ovid.t <- tm_map(ovid.t, removeWords, stopwords("english"))
ovid.t <- tm_map(ovid.t, removePunctuation, preserve_intra_word_dashes = T)
ovid.t <- tm_map(ovid.t, stripWhitespace)
# Chunk 6
# Chunk 7
dtm <- DocumentTermMatrix(ovid.t) #Function to create matrix
dim(dtm)
# Chunk 8
inspect(dtm[1:5, 10:13])
# Chunk 9
findFreqTerms(dtm, 150)
# Chunk 10
wordcloud(tm_map(ovid.t, PlainTextDocument), min.freq=100, scale=c(5,2),
random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
# Chunk 11
dtm <- removeSparseTerms(dtm, 0.4)
dim(dtm)
inspect(dtm[1:5, 10:13])
dtm.df <- as.data.frame(as.matrix(dtm))
# Chunk 12
InaugurationInfo$Key <- paste("inaug", InaugurationInfo$File, "-",InaugurationInfo$Term, ".txt", sep = "")
dtm.df$Key <- rownames(dtm.df) #Creates a key which will be used to link the tables
dtm.df <- merge(x = dtm.df, y = InaugurationInfo[,c(4,6)])
#Reshape and adequate the dataframe format before merging
ds <- reshape(dates.speeches, direction = "long", varying = list(2:5), v.names = "SpeechDates")
ds <- ds[!ds$SpeechDates == "", c(1:3)]
ds$SpeechDates <- as.Date(ds$SpeechDates, "%m/%d/%Y")
names(ds) <- c("President", "Term", "SpeechDate")
ds$Key <- paste("inaug", sapply(ds$President, gsub, pattern = " ", replacement = ""), "-",ds$Term, ".txt", sep = "")
# Chunk 13
par(mfrow = c(1,2))
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Democratic"), which(sapply(dtm.df, is.numeric))]), freq = colSums(dtm.df[which(dtm.df$Party == "Democratic"), which(sapply(dtm.df, is.numeric))]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Democrats", x = 0.5, y = 1.1, cex = 2)
wordcloud(words = names(dtm.df[which(dtm.df$Party == "Republican"), which(sapply(dtm.df, is.numeric))]), freq = colSums(dtm.df[which(dtm.df$Party == "Republican"), which(sapply(dtm.df, is.numeric))]), min.freq=60, scale=c(5,1), random.color=T, max.word=60, random.order=F,colors=brewer.pal(8,"Dark2"))
text(labels = "Republicans", x = 0.5, y = 1.1, cex = 2)
# Chunk 14
Cluster.model2 <- kmeans(dtm, 2, iter.max = 15, nstart = 10)
Cluster.model3 <- kmeans(dtm, 3, iter.max = 15, nstart = 10)
dtm.df$Cluster2 <- Cluster.model2$cluster
dtm.df$Cluster3 <- Cluster.model3$cluster
# Chunk 15
dtm.df$Cl
# Chunk 16
PCA.model <- prcomp(dtm)
plot(PCA.model$sdev, type = "l", col = "blue")
points(PCA.model$sdev, pch = 22, bg = "red")
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Party)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster1)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster2)))
dtm.df$Cl
table(dtm.df[ ,c("Party", "Cluster2")])
table(dtm.df[ ,c("Party", "Cluster3")])
Cluster.model2 <- kmeans(dtm, 2, iter.max = 15, nstart = 10)
Cluster.model3 <- kmeans(dtm, 3, iter.max = 15, nstart = 10)
Cluster.model4 <- kmeans(dtm, 4, iter.max = 15, nstart = 10)
dtm.df$Cluster2 <- Cluster.model2$cluster
dtm.df$Cluster3 <- Cluster.model3$cluster
dtm.df$Cluster4 <- Cluster.model4$cluster
table(dtm.df[ ,c("Party", "Cluster2")])
table(dtm.df[ ,c("Party", "Cluster3")])
table(dtm.df[ ,c("Party", "Cluster4")])
?kmeans
ifelse(dtm.df$Party == "Republican" | dtm.df$Party == "Democratic", dtm.df$Party, "Other")
as.character(dtm.df$Party)
ifelse(dtm.df$Party == "Republican" | dtm.df$Party == "Democratic", as.character(dtm.df$Party), "Other")
dtm.df$Party <- ifelse(dtm.df$Party == "Republican" | dtm.df$Party == "Democratic", as.character(dtm.df$Party), "Other")
PCA.model$sdev
PCA.model$sdev/sum(PCA.model$sdev)
PCA.model$sdev/sum(PCA.model$sdev)*100
summary(PCA)
summary(PCA.model)
PCA.model$sdev/sum(PCA.model$sdev)*100
(PCA.model$sdev^2)/sum(PCA.model$sdev^2)*100
plot((PCA.model$sdev^2)/sum(PCA.model$sdev^2)*100, type = "l", col = "blue", ylab = "Prop. of Variance", xlab = "PC")
points((PCA.model$sdev^2)/sum(PCA.model$sdev^2)*100, pch = 22, bg = "red")
?svm
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster2)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Cluster2), pch = as.factor(dtm.df$Party)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(col = as.factor(dtm.df$Party)))
ggplot(data = as.data.frame(PCA.model$x[,1:2]), aes(PC1, PC2)) +
geom_point(aes(pch = as.factor(dtm.df$Cluster2), col = as.factor(dtm.df$Party)))
?qda
View(dtm.df)
?subset
?subset
dtm.qda <- subset(dtm.df, select = -c(Cluster2))
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4))
View(dtm.df)
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key))
View(dtm.qda)
QDA.model <- qda(Party ~., data = dtm.qda)
?qda
library(MASS)
QDA.model <- qda(Party ~., data = dtm.qda)
colSums(dtm.qda)
colSums(dtm.qda[,-ncol(dtm.qda)])
View(dtm.qda)
?subset
dtm.qda <- dtm.qda[-which(dtm.qda$Party == "Other"),]
QDA.model <- qda(Party ~., data = dtm.qda)
QDA.model <- qda(Party ~ american, data = dtm.qda)
QDA.model
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key))
QDA.model <- qda(Party ~ american, data = dtm.qda)
QDA.model
?qda
QDA.model$lev
pred <- predict(QDA.model)
pred
QDA.model$class
pred <- predict(QDA.model)$class
pred
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key))
QDA.model <- qda(Party ~ ., data = dtm.qda)
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key, confidence))
QDA.model <- qda(Party ~ ., data = dtm.qda)
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key, confidence, year))
QDA.model <- qda(Party ~ ., data = dtm.qda)
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key))
QDA.model <- qda(Party ~ american, data = dtm.qda)
QDA.model
QDA.model$class
pred <- predict(QDA.model)$class
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key))
QDA.model <- qda(Party ~ american + among + best, data = dtm.qda)
QDA.model
QDA.model$class
pred <- predict(QDA.model)$class
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
QDA.model <- qda(Party ~ american + among + best + can + citzens + come, data = dtm.qda)
QDA.model
QDA.model$class
pred <- predict(QDA.model)$class
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
QDA.model <- qda(Party ~ american + among + best + can + citzens + come + common + confidence + constitution, data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution, data = dtm.qda)
QDA.model
QDA.model$class
pred <- predict(QDA.model)$class
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key))
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + day + duty, data = dtm.qda)
QDA.model
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty, data = dtm.qda)
QDA.model
QDA.model$class
pred <- predict(QDA.model)$class
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
QDA.model <- qda(Party ~ ., data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + equal + even + ever, data = dtm.qda)
QDA.model
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + equal + ever, data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + equal + even, data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + even + ever, data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + ever, data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + government + every, data = dtm.qda)
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key, day))
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + government, data = dtm.qda)
QDA.model
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + government, data = dtm.qda)
dtm.qda <- subset(dtm.df, select = -c(Cluster2, Cluster3, Cluster4, Key, day))
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty + government, data = dtm.qda)
QDA.model <- qda(Party ~ american + among + best + can + citizens + come + common + confidence + constitution + country + duty, data = dtm.qda)
QDA.model
QDA.model$class
pred <- predict(QDA.model)$class
error <- sum(pred != dtm.qda$Party)
error.rate <- error/length(dtm.qda$Party)
error.rate
error
pred
dtm.qda$Party
a <- tm_map(ovid.t, nchar)
a
?lapply
a <- sapply(ovid, nchar)
a
a <- sapply(content(ovid), nchar)
a
a <- sapply(content(ovid), nchar)$content
a <- sapply(content(ovid), nchar)[1,]
a
b <- sapply(content(ovid.t), nchar)[1,]
b
full.char <- sapply(content(ovid), nchar)[1,]
partial.char <- sapply(content(ovid.t), nchar)[1,]
rm(a,b)
rm(dtm.qda)
barplot(full.char - partial.char)
par(mfrow=c(1,1))
full.char <- sapply(content(ovid), nchar)[1,]
partial.char <- sapply(content(ovid.t), nchar)[1,]
barplot(full.char - partial.char)
?barplot
prolix.measure <- full.char - partial.char
ggplot(data = prolix.measure, aes(y = prolix.measure))) +
geom_bar(col = "blue")
ggplot(data = prolix.measure, aes(y = prolix.measure)) +
geom_bar(col = "blue")
ggplot(data = prolix.measure, aes(y = as.numeric(prolix.measure))) +
geom_bar(col = "blue")
?barplot
n <- meta(ovid, "author")
n
n <- unlist(meta(ovid, "author"))
n
barplot(full.char - partial.char, horiz = T)
full.char - partial.char
barplot(full.char - partial.char, horiz = T, args.legend = n)
n <- meta(ovid, "author")
n
names(n)
n <- names(meta(ovid, "author"))
barplot(full.char - partial.char, horiz = T, args.legend = n)
n
ggplot(data = full.char - partial.char, aes(x = n)) +
geom_bar(stat="identity")
prolix.df <- data.frame(full.char - partial.char, n)
View(prolix.df)
ggplot(data = prolix.df, aes(x = n)) +
geom_bar(stat="identity")
ggplot(data = prolix.df, aes(x = Speech, y = Number of Char)) +
geom_bar(stat="identity")
names(prolix.df) <- c("Number of Char", "Speech")
ggplot(data = prolix.df, aes(x = Speech, y = Number of Char)) +
geom_bar(stat="identity")
names(prolix.df) <- c("Number of char", "Speech")
ggplot(data = prolix.df, aes(x = Speech, y = Number of Char)) +
geom_bar(stat="identity")
ggplot(data = prolix.df, aes(x = Speech, y = Number of Char)) +
geom_bar()
names(prolix.df) <- c("Number", "Speech")
ggplot(data = prolix.df, aes(x = Speech, y = Number)) +
geom_bar()
ggplot(data = prolix.df, aes(x = Speech, y = Number)) +
geom_bar(stat = "identity")
